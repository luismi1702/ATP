{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2db03ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import helium\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2ef659",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SERVE LEADERS \n",
    "\n",
    "serve_leaders = list()\n",
    "\n",
    "# 52 weeks:\n",
    "\n",
    "url = f\"https://www.atptour.com/en/stats/leaderboard?boardType=serve&timeFrame=52Week&surface=all&versusRank=all&formerNo1=false\"\n",
    "browser = helium.start_chrome(url, headless = False)\n",
    "\n",
    "sleep(10)\n",
    "\n",
    "soup = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "\n",
    "serve_leaders.append(soup)\n",
    "    \n",
    "browser.close()\n",
    "\n",
    "# PLAYER\n",
    "ply = soup.find_all(\"a\", class_=\"stats-player-name\")\n",
    "player = [i.text.split(\",\")[0] for i in ply]\n",
    "\n",
    "# SERVE RATING\n",
    "serve_ratings = [td.text for item in serve_leaders for td in item.find_all('td', {'data-type': 'serveRating'})]\n",
    "\n",
    "# 1ST SERVE\n",
    "serve_1st = [s1.text for item in serve_leaders for s1 in item.find_all('td', {'data-type': '1stServePct'})]\n",
    "# 1st SERVE POINTS WON\n",
    "serve_pwon = [spw.text for item in serve_leaders for spw in item.find_all('td', {'data-type': '1stServePointsWonPct'})]\n",
    "# 2ND SERVE POINTS WON\n",
    "serve2_pwon = [sp2w.text for item in serve_leaders for sp2w in item.find_all('td', {'data-type': '2ndServePointsWonPct'})]\n",
    "# SERVE GAMES WON\n",
    "serve_gameswon = [sgw.text for item in serve_leaders for sgw in item.find_all('td', {'data-type': 'serviceGamesWonPct'})]\n",
    "# AVG. ACES / MATCH\n",
    "avg_match = [avgm.text for item in serve_leaders for avgm in item.find_all('td', {'data-type': 'avgAcesPerMatch'})]\n",
    "# AVG.DOUBLE FAULTS\n",
    "avg_dfaults = [avgf.text for item in serve_leaders for avgf in item.find_all('td', {'data-type': 'avgDblFaultsPerMatch'})]\n",
    "\n",
    "\n",
    "# OBTENEMOS EL DATAFRAME Y GUARDAMOS EN CSV. \n",
    "\n",
    "df = pd.DataFrame({\"Player\": player,\"Serve Rating\": serve_ratings, \"% 1st Serve\": serve_1st, \"% 1st Serve Points Won\": serve_pwon, \"% 2nd Serve Points Won\": serve2_pwon, \"% Serve Games Won\" : serve_gameswon, \"Avg.Aces/ Match\": avg_match, \"Avg.Double Faults/Match\" : avg_dfaults })\n",
    "\n",
    "df.to_csv(\"Serve_Leaders.csv\", index = False, sep = \",\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fbdf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RETURN LEADERS\n",
    "\n",
    "return_leaders = list()\n",
    "\n",
    "url = f\"https://www.atptour.com/en/stats/leaderboard?boardType=return&timeFrame=52Week&surface=all&versusRank=all&formerNo1=false\"\n",
    "browser = helium.start_chrome(url, headless = False)\n",
    "\n",
    "sleep(10)\n",
    "\n",
    "soup = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "\n",
    "return_leaders.append(soup)\n",
    "    \n",
    "browser.close()\n",
    "\n",
    "# PLAYER\n",
    "players = [a.text for item in return_leaders for tr in item.find_all('tr', class_='stats-listing-row') for a in tr.find_all('a', class_='stats-player-name')]\n",
    "# RETURN RATING\n",
    "return_ratings = [rtr.text for item in return_leaders for rtr in item.find_all('td', {'data-type': 'returnRating'})]\n",
    "#% 1 ST SERVE RETURN POINTS WON\n",
    "return1_pwon = [srpw.text for item in return_leaders for srpw in item.find_all('td', {'data-type': '1stServeReturnPointsWonPct'})]\n",
    "# % 2ND SERVE RETURN POINTS WON\n",
    "return2_pwon = [sr2pw.text for item in return_leaders for sr2pw in item.find_all('td', {'data-type': '2ndServeReturnPointsWonPct'})]\n",
    "# % RETURN GAMES WON\n",
    "return_games = [rgames.text for item in return_leaders for rgames in item.find_all('td', {'data-type': 'returnGamesWonPct'})]\n",
    "# % BREAK POINTS CONVERTED\n",
    "break_points = [bpoints.text for item in return_leaders for bpoints in item.find_all('td', {'data-type': 'brkPointsConvertedPct'})]\n",
    "\n",
    "\n",
    "#GUARDAMOS DATOS EN UN DATAFRAME Y GUARDAMOS EN CSV : \n",
    "\n",
    "df = pd.DataFrame({\"Player\": players,\"Return Rating\": return_ratings, \"% 1st Serve Return Points Won\": return1_pwon, \"% 2nd Serve Return Points Won\": return2_pwon, \"Return Games Won\": return_games, \"Break Points Converted\" : break_points})\n",
    "\n",
    "df.to_csv(\"Return_Leaders.csv\", index = False, sep = \",\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95bed9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNDER PRESSURE LEADERS\n",
    "\n",
    "under_leaders = list()\n",
    "\n",
    "url = f\"https://www.atptour.com/en/stats/leaderboard?boardType=pressure&timeFrame=52Week&surface=all&versusRank=all&formerNo1=false\"\n",
    "browser = helium.start_chrome(url, headless = False)\n",
    "\n",
    "sleep(10)\n",
    "\n",
    "soup = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "\n",
    "under_leaders.append(soup)\n",
    "    \n",
    "browser.close()\n",
    "\n",
    "\n",
    "# PLAYER UNDER PRESSURE\n",
    "players1 = [a.text for item in under_leaders for tr in item.find_all('tr', class_='stats-listing-row') for a in tr.find_all('a', class_='stats-player-name')]\n",
    "# UNDER PRESSSURE RATING\n",
    "underp_ratings = [uprat.text for item in under_leaders for uprat in item.find_all('td', {'data-type': 'pressureRating'})]\n",
    "# % BREAK POINTS CONVERTED\n",
    "breakp_converted = [bpconv.text for item in under_leaders for bpconv in item.find_all('td', {'data-type': 'brkPointsConvertedPct'})]\n",
    "# % BREAK POINTS SAVED\n",
    "breakp_saved = [bpsav.text for item in under_leaders for bpsav in item.find_all('td', {'data-type': 'brkPointsSavedPct'})]\n",
    "# TIE BREAKS WON\n",
    "tie_won = [twon.text for item in under_leaders for twon in item.find_all('td', {'data-type': 'tieBreaksWonPct'})]\n",
    "# % DECIDING SETS WON\n",
    "dset_won = [dswon.text for item in under_leaders for dswon in item.find_all('td', {'data-type': 'decidingSetsWonPct'})]\n",
    "\n",
    "\n",
    "#GUARDAMOS DATOS EN UN DATAFRAME Y GUARDAMOS EN CSV : \n",
    "\n",
    "df = pd.DataFrame({\"Player\": players1,\"Under Pressure Rating\": underp_ratings, \"% Break Points Converted\": breakp_converted, \"% Break points Saved\": breakp_saved, \"Tie Breaks Won\": tie_won, \"% Deciding Sets Won\" : dset_won})\n",
    "\n",
    "df.to_csv(\"UnderPressure_Leaders.csv\", index = False, sep = \",\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c701b654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIN / LOSS\n",
    "\n",
    "win_loss = list()\n",
    "\n",
    "url = f\"https://www.atptour.com/en/stats/win-loss-index\"\n",
    "browser = helium.start_chrome(url, headless = False)\n",
    "\n",
    "sleep(10)\n",
    "\n",
    "soup = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "\n",
    "win_loss.append(soup)\n",
    "    \n",
    "browser.close()\n",
    "\n",
    "\n",
    "# PLAYERS WIN/LOSS\n",
    "players2 = [pwl.text for item in win_loss for pwl in item.find_all('td', class_='player-cell')]\n",
    "# YTD INDEX\n",
    "indexes = [td.text for item in win_loss for td in item.find_all('td', class_='fifty-two-week-index-cell')]\n",
    "# YTD TITLES\n",
    "titles = [ttl.text.replace(\"\\t\",\"\") for item in win_loss for ttl in item.find_all('td', class_='fifty-two-week-titles-cell')]\n",
    "# YTD WIN/LOSS\n",
    "winloss = [ywlss.text for item in win_loss for ywlss in item.find_all('td', class_='fifty-two-week-win-loss-cell')]\n",
    "\n",
    "\n",
    "#GUARDAMOS DATOS EN UN DATAFRAME Y GUARDAMOS EN CSV : \n",
    "\n",
    "df = pd.DataFrame({\"Player\": players2,\"YTD Index\": indexes, \"YTD Titles\": titles, \"YTD Win/Loss\": winloss})\n",
    "\n",
    "df.to_csv(\"win_loss.csv\", index = False, sep = \",\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecb101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANKINGS --> SINGLES TOP 100\n",
    "\n",
    "ranking_singles = list()\n",
    "\n",
    "days = date.today().strftime(\"%y-%m-%d\")\n",
    "\n",
    "url = f\"https://www.atptour.com/en/rankings/singles?rankRange=1-5000&rankDate={days}\"\n",
    "browser = helium.start_chrome(url, headless = False)\n",
    "\n",
    "sleep(10)\n",
    "\n",
    "soup = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "ranking_singles.append(soup)\n",
    "\n",
    "browser.close()\n",
    "\n",
    "#OBTENEMOS LOS DATOS DE LA TABLA ################################\n",
    "\n",
    "rank_1 = [td.text.replace(\"\\n\",\"\") for item in ranking_singles for table in item.find_all('table', class_='mega-table') for td in table.find_all('td', class_='rank-cell border-left-4 border-right-dash-1')]\n",
    "\n",
    "rank_2 = [rnk.text.replace(\"\\n\",\"\") for item in ranking_singles for rnk in item.find_all('td', class_='move-cell border-right-4 border-left-dash-1')]\n",
    "\n",
    "players3 = [pyl3.text.replace(\"\\n\",\"\") for item in ranking_singles for pyl3 in item.find_all('td', class_='player-cell border-left-dash-1 border-right-dash-1')]\n",
    "\n",
    "edad = [ag.text.replace(\"\\n\",\"\") for item in ranking_singles for ag in item.find_all('td', class_='age-cell border-left-dash-1 border-right-4')]\n",
    "\n",
    "points = [pts.text.replace(\"\\n\",\"\") for item in ranking_singles for pts in item.find_all('td', class_='points-cell border-right-dash-1')]\n",
    "\n",
    "pt_1 = [pt1.text.replace(\"\\n\",\"\") for item in ranking_singles for pt1 in item.find_all('td', class_='points-move-cell border-right-dash-1')]\n",
    "\n",
    "tplayed = [tpy.text.replace(\"\\n\",\"\") for item in ranking_singles for tpy in item.find_all('td', class_=\"tourn-cell border-left-dash-1 border-right-dash-1\")]\n",
    "\n",
    "dppg = [dpg.text.replace(\"\\n\",\"\") for item in ranking_singles for dpg in item.find_all('td', class_='pts-cell border-left-dash-1 border-right-dash-1')]\n",
    "\n",
    "nbest = [nbst.text.replace(\"\\n\",\"\") for item in ranking_singles for nbst in item.find_all('td', class_='next-cell border-left-dash-1 border-right-4')]\n",
    "\n",
    "#GUARDAMOS DATOS EN UN DATAFRAME Y GUARDAMOS EN CSV : \n",
    "\n",
    "df = pd.DataFrame({\"Ranking\":rank_1,\"+/- Ranking\": rank_2, \"Player\": players3,\"Age\": edad, \"Points\": points, \"+/- Points\" : pt_1, \"Tourn Player\": tplayed, \"Dropping\": dppg , \"Next Best\" : nbest })\n",
    "\n",
    "# Eliminamos enumeracion automatica ya que el ranking nos lo posiciona.\n",
    "\n",
    "ranking = df.style.hide_index()\n",
    "\n",
    "df.to_csv(\"ranking_singles.csv\", index = False, sep = \",\")\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
